{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a030ad3f-d3d1-4207-8225-b03146023989",
   "metadata": {},
   "source": [
    "# Classification\n",
    "A classification strategy is used when the tags are not **continuous**, but **categorical**. \n",
    "\n",
    "### Examples for binary classification\n",
    "- Spam detector (yes/no)\n",
    "- Default loan (yes/no)\n",
    "- Diagnosis of a disease (yes/no)\n",
    "\n",
    "Support Vector             |  Logisitic Regression\n",
    ":-------------------------:|:-------------------------:\n",
    "![Support Vector](images/svm.png \"Support Vector\")  |  ![Logistic Regression](images/logistic.png \"Logistic Regression\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e277a5-b2c4-45dd-909e-d912b1ed0182",
   "metadata": {},
   "source": [
    "## Classification Algorithms in Spark\n",
    "- Logistic Regression\n",
    "- Support Vector Classifier\n",
    "- Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b58f6d-c27e-4918-b63d-a2abba56f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark =  SparkSession.builder.appName('Classification').getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"titanic.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c341efa-ba2f-4df8-b99e-469d6a4ccbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd24fd0-2f67-4301-ba76-e7d1518b8445",
   "metadata": {},
   "source": [
    "## Transformation of categorical variables\n",
    "String variables will need to be transformed in numerical tapes in order to be processed by Spark's ML library. \n",
    "We can use a String Indexer, or a One-Hot Encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3974f19-91c1-454d-8115-ab5930159afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "si = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "si_fit = si.fit(df) # model pentru indexer\n",
    "\n",
    "df_indexed = si_fit.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748c0c4-e3b8-4457-be83-2da2dc1358db",
   "metadata": {},
   "source": [
    "### Caution!\n",
    "One-Hot Encoding only works for numerical values. We will use the **'SexIndex'** column, which has already been transformed in numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d35680d-9154-4374-9501-a53b1fd3a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "ohe = OneHotEncoder(inputCol='SexIndex', outputCol='SexEncoded')\n",
    "ohe_fit = ohe.fit(df_indexed)\n",
    "df_encoded = ohe_fit.transform(df_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606788e5-306d-4f0d-8555-4aa3f37abeab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+\n",
      "|   Sex|SexIndex|   SexEncoded|\n",
      "+------+--------+-------------+\n",
      "|  male|     0.0|(1,[0],[1.0])|\n",
      "|  male|     0.0|(1,[0],[1.0])|\n",
      "|female|     1.0|    (1,[],[])|\n",
      "|female|     1.0|    (1,[],[])|\n",
      "|  male|     0.0|(1,[0],[1.0])|\n",
      "+------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_encoded.orderBy('Age').select(['Sex', 'SexIndex', 'SexEncoded']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306743b0-5b1d-4a2f-bb46-69986e892fec",
   "metadata": {},
   "source": [
    "### Splitting the data before assembling\n",
    "We will use compare the two encodings, therefore we will like to process the same data. \n",
    "The split data will be used to create two types of data: indexed and one-hot encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b48b8f-5420-4a29-9717-e6f71e39ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df_encoded.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b6861d-b66e-4e0c-a154-9e524a004966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'SexIndex']\n",
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'SexIndex', 'SexEncoded']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "print(df_indexed.columns)\n",
    "print(df_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd68173d-a828-4a43-abdc-478b9efcf3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembler_index = VectorAssembler(inputCols=['SexIndex', 'Age', 'SibSp', 'Parch', 'Fare'], outputCol='features')\n",
    "assembler_encode = VectorAssembler(inputCols=['SexEncoded', 'Age', 'SibSp', 'Parch', 'Fare'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e34ec9b-92e8-4414-81df-29734d3ded50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i_df_train = assembler_index.transform(train_df)\n",
    "e_df_train = assembler_encode.transform(train_df)\n",
    "i_df_test = assembler_index.transform(test_df)\n",
    "e_df_test = assembler_encode.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f083ea-042d-43cf-a878-871827501d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i_df_train = i_df_train.select(['features', 'Survived'])\n",
    "e_df_train = e_df_train.select(['features', 'Survived'])\n",
    "\n",
    "i_df_test = i_df_test.select(['features', 'Survived'])\n",
    "e_df_test = e_df_test.select(['features', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad067d3-e4f9-45f7-b5a8-5ff80e3fa951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------+\n",
      "|features                 |Survived|\n",
      "+-------------------------+--------+\n",
      "|[0.0,0.92,1.0,2.0,151.55]|1       |\n",
      "|[0.0,2.0,1.0,1.0,26.0]   |1       |\n",
      "|[0.0,3.0,1.0,1.0,26.0]   |1       |\n",
      "|[1.0,4.0,2.0,1.0,39.0]   |1       |\n",
      "|[0.0,11.0,1.0,2.0,120.0] |1       |\n",
      "+-------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------------+--------+\n",
      "|features                 |Survived|\n",
      "+-------------------------+--------+\n",
      "|[1.0,0.92,1.0,2.0,151.55]|1       |\n",
      "|[1.0,2.0,1.0,1.0,26.0]   |1       |\n",
      "|[1.0,3.0,1.0,1.0,26.0]   |1       |\n",
      "|[0.0,4.0,2.0,1.0,39.0]   |1       |\n",
      "|[1.0,11.0,1.0,2.0,120.0] |1       |\n",
      "+-------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i_df_train.orderBy('Age').show(5, truncate=False)\n",
    "e_df_train.orderBy('Age').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a62511-68b0-4cb9-b02c-656e15edb47f",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ff12ce-8f98-4e03-844e-8842fd5a32c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "log_reg = LogisticRegression(labelCol='Survived')\n",
    "i_log_reg_model = log_reg.fit(i_df_train)\n",
    "e_log_reg_model = log_reg.fit(e_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb01607-91d9-4027-b2a9-72c14b7b68b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|            features|Survived|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|[1.0,38.0,1.0,0.0...|     1.0|[-3.0613390853823...|[0.04473044952251...|       1.0|\n",
      "|[1.0,58.0,0.0,0.0...|     1.0|[-1.9596293631014...|[0.12350716457662...|       1.0|\n",
      "|(5,[1,4],[28.0,35...|     1.0|[-0.0529499238256...|[0.48676561099766...|       1.0|\n",
      "|[1.0,49.0,1.0,0.0...|     1.0|[-2.5693546778128...|[0.07113693289700...|       1.0|\n",
      "|[0.0,65.0,0.0,1.0...|     0.0|[2.02643540437449...|[0.88354480578035...|       0.0|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|            features|Survived|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|[0.0,38.0,1.0,0.0...|     1.0|[-3.0613390853823...|[0.04473044952251...|       1.0|\n",
      "|(5,[1,4],[58.0,26...|     1.0|[-1.9596293631014...|[0.12350716457662...|       1.0|\n",
      "|[1.0,28.0,0.0,0.0...|     1.0|[-0.0529499238256...|[0.48676561099766...|       1.0|\n",
      "|[0.0,49.0,1.0,0.0...|     1.0|[-2.5693546778128...|[0.07113693289700...|       1.0|\n",
      "|[1.0,65.0,0.0,1.0...|     0.0|[2.02643540437449...|[0.88354480578035...|       0.0|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i_log_reg_model.summary.predictions.show(5)\n",
    "e_log_reg_model.summary.predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f84273-e369-48fa-8bfe-aaec26fd1432",
   "metadata": {},
   "source": [
    "## How to evaluate the model?\n",
    "- using a *confusion matrix* https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad096fe-ad91-4c65-8cc1-33aef8e29091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923076923076923\n",
      "[0.68, 0.8625]\n",
      "[0.7555555555555555, 0.8117647058823529]\n",
      "[0.7157894736842104, 0.8363636363636364]\n"
     ]
    }
   ],
   "source": [
    "print(i_log_reg_model.summary.accuracy)\n",
    "print(i_log_reg_model.summary.precisionByLabel)\n",
    "print(i_log_reg_model.summary.recallByLabel)\n",
    "print(i_log_reg_model.summary.fMeasureByLabel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0246cc9b-f8a8-4d84-bfd8-e48f9e5cdee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = i_log_reg_model.evaluate(i_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dd3a0b5-01f2-436a-b4c1-88bacd09c3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.BinaryLogisticRegressionSummary"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0892bbb-5b80-4997-82f2-547785ba0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7358490566037735\n",
      "[0.5238095238095238, 0.875]\n",
      "[0.7333333333333333, 0.7368421052631579]\n"
     ]
    }
   ],
   "source": [
    "print(results.accuracy)\n",
    "print(results.precisionByLabel)\n",
    "print(results.recallByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92956e14-35c2-44ad-a133-d0ed29bb2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "168c329a-6f62-4317-b007-000689db45db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = i_log_reg_model.transform(i_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1527e016-91a1-40fd-957d-e70aa44f4b23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|            features|Survived|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|[1.0,35.0,1.0,0.0...|       1|[-3.2050846336377...|[0.03897482675231...|       1.0|\n",
      "|(5,[1,4],[54.0,51...|       0|[1.11192229525615...|[0.75248731297708...|       0.0|\n",
      "|[1.0,4.0,1.0,1.0,...|       1|[-4.1837968702347...|[0.01501174429455...|       1.0|\n",
      "|(5,[1,4],[34.0,13...|       1|[0.20081062040338...|[0.55003463118061...|       0.0|\n",
      "|[0.0,19.0,3.0,2.0...|       0|[-0.1983626356232...|[0.45057131048745...|       1.0|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc4c44-2d21-4acd-bb7c-1c4f482d63b9",
   "metadata": {},
   "source": [
    "## Evaluators\n",
    "\n",
    "### Binary Classification Evaluator\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.BinaryClassificationEvaluator.html\n",
    "\n",
    "#### Metrics\n",
    "- areaUnderROC (area under ROC Curve) -> AUC\n",
    "- areaUnderPR (area under Precission/Recall) -> AUPR\n",
    "\n",
    "AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n",
    "\n",
    "One axis of ROC and PR curves is the same, that is TPR: how many positive cases have been classified correctly out of all positive cases in the data.\n",
    "\n",
    "The other axis is different. ROC uses FPR, which is how many mistakenly declared positives out of all negatives in the data. PR curve uses precision: how many true positives out of all that have been predicted as positives. So the base of the second axis is different. ROC uses what's in the data, PR uses what's in the prediction as a basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd32b8-b05e-4596-b0e7-2714acb82a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35be757a-1cff-455e-bdc8-292d70defd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0caca907-d430-49b2-b9a6-613f43f63d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d32022-5ac6-4aa7-aef6-bb34ac5f6e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7350877192982457\n"
     ]
    }
   ],
   "source": [
    "roc = bin_eval.evaluate(predictions)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5eba870-0bc4-458a-ac5c-03f996ed2a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854208043694141\n"
     ]
    }
   ],
   "source": [
    "auPR = bin_eval.evaluate(predictions, {bin_eval.metricName: \"areaUnderPR\"})\n",
    "print(auPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6f1f1-8559-4b1b-803a-bf3131d97e1d",
   "metadata": {},
   "source": [
    "## String Indexer vs. OneHotEncoder\n",
    "### Comparing the two techniques for categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4ae4c91-f4be-4a4e-991c-d591cb52615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimentLogReg(train_df, test_df, labelCol='label'):\n",
    "    log_reg = LogisticRegression(labelCol=labelCol)\n",
    "    bin_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol=labelCol)\n",
    "    model = log_reg.fit(train_df)\n",
    "\n",
    "    results = model.evaluate(test_df)\n",
    "    \n",
    "    print(\"Accuracy: \", results.accuracy)\n",
    "    print(\"Precission by Label: \", results.precisionByLabel)\n",
    "    print(\"Recall by Label: \", results.recallByLabel)\n",
    "    \n",
    "    pred = model.transform(test_df)\n",
    "    roc = bin_eval.evaluate(pred)\n",
    "    print(\"Area under ROC curve\", roc)\n",
    "    auPR = bin_eval.evaluate(predictions, {bin_eval.metricName: \"areaUnderPR\"})\n",
    "    print(\"Area under PR curve\", auPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dce30b2-c0dc-4f82-99b6-5e2e648d22da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7358490566037735\n",
      "Precission by Label:  [0.5238095238095238, 0.875]\n",
      "Recall by Label:  [0.7333333333333333, 0.7368421052631579]\n",
      "Area under ROC curve 0.7350877192982457\n",
      "Area under PR curve 0.854208043694141\n",
      "Accuracy:  0.7358490566037735\n",
      "Precission by Label:  [0.5238095238095238, 0.875]\n",
      "Recall by Label:  [0.7333333333333333, 0.7368421052631579]\n",
      "Area under ROC curve 0.7350877192982457\n",
      "Area under PR curve 0.854208043694141\n"
     ]
    }
   ],
   "source": [
    "experimentLogReg(i_df_train, i_df_test, labelCol='Survived')\n",
    "experimentLogReg(e_df_train, e_df_test, labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffba2163-d619-41ef-8ea2-e9f7f2b31719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "def experiment_classification(train_df, test_df, labelCol='label'):\n",
    "    log_reg = LogisticRegression(labelCol=labelCol)\n",
    "    bayes = NaiveBayes(labelCol=labelCol)\n",
    "    svm = LinearSVC(labelCol=labelCol)\n",
    "    alg_names = ['Logistic Regression', 'Naive Bayes', 'SVM']\n",
    "    algs = [log_reg, bayes, svm]\n",
    "\n",
    "    bin_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol=labelCol)\n",
    "    for i in range(len(algs)):\n",
    "        alg = algs[i]\n",
    "        print(alg_names[i], \":\")\n",
    "        \n",
    "        model = alg.fit(train_df)\n",
    "        \n",
    "        pred = model.transform(test_df)\n",
    "        roc = bin_eval.evaluate(pred)\n",
    "        print(\"Area under ROC curve\", roc)\n",
    "        auPR = bin_eval.evaluate(predictions, {bin_eval.metricName: \"areaUnderPR\"})\n",
    "        print(\"Area under PR curve\", auPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4e1bc07-c961-4ffb-b5d2-24d87053e449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :\n",
      "Area under ROC curve 0.7350877192982457\n",
      "Area under PR curve 0.854208043694141\n",
      "Naive Bayes :\n",
      "Area under ROC curve 0.662280701754386\n",
      "Area under PR curve 0.854208043694141\n",
      "SVM :\n",
      "Area under ROC curve 0.7228070175438597\n",
      "Area under PR curve 0.854208043694141\n"
     ]
    }
   ],
   "source": [
    "experiment_classification(i_df_train, i_df_test, labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d77ce5b8-6b58-4b1c-a5a6-a06a18682fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :\n",
      "Area under ROC curve 0.7350877192982457\n",
      "Area under PR curve 0.854208043694141\n",
      "Naive Bayes :\n",
      "Area under ROC curve 0.6228070175438597\n",
      "Area under PR curve 0.854208043694141\n",
      "SVM :\n",
      "Area under ROC curve 0.7228070175438597\n",
      "Area under PR curve 0.854208043694141\n"
     ]
    }
   ],
   "source": [
    "experiment_classification(e_df_train, e_df_test, labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1bbb4-1fed-4c3b-835a-dac72362eff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
